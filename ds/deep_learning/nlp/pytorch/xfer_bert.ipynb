{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2727ba-6be0-4620-a1eb-3d219a40123a",
   "metadata": {},
   "source": [
    "pip install torch torchvision torchaudio\n",
    "pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a41395-3138-4ced-9697-a1e961f81198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-19 12:29:46.557942: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 12:29:47.805756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 12:29:49.850268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b35d1c-77af-4154-a792-4232819908e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "dataset = load_dataset('imdb')\n",
    "# Use only a subset for training to keep it quick\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select([i for i in range(1000)])\n",
    "test_dataset = dataset['test'].shuffle(seed=42).select([i for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bd817b-0498-47c6-a4f4-84c39eeb31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define a tokenization function\n",
    "def tokenize_function(examples):\n",
    "\treturn tokenizer(examples['text'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0480d0da-5588-4c1e-b88e-7634a3f20b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f513d2-0f2c-483a-8048-e1282f0e29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Create Data Loaders\n",
    "# Create PyTorch data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9578e451-8417-4678-96bc-ed384437a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e7f034-503c-47f0-9930-a68fd3fa5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "\u001b[K     |████████████████████████████████| 314 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: torch>=1.10.0 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: psutil in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied, skipping upgrade: safetensors>=0.3.1 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied, skipping upgrade: huggingface-hub in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from accelerate) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>=1.17 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied, skipping upgrade: sympy in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied, skipping upgrade: triton==2.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied, skipping upgrade: networkx in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied, skipping upgrade: fsspec in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=4.8.0 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.42.1 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied, skipping upgrade: mpmath<1.4,>=1.1.0 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-nvjitlink-cu12 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate) (12.5.82)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2.2.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /home/ggupte/practice/ds/deep_learning/venv-deep-learn/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.32.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d7a7200-490c-4a63-a546-eb5d763021fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Training Arguments and Trainer\n",
    "#The Trainer class simplifies the training process significantly.\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=16,  # Batch size for training\n",
    "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Create a trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # The instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # Training arguments\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=test_dataset            # Evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf0bd2-4567-402d-855a-cc4fbd98ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Train the Model\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\t\n",
    "#9. Evaluate the Model\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803eca41-7266-40a4-a466-796ad0d93141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Save the Model\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./sentiment_model')\n",
    "tokenizer.save_pretrained('./sentiment_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ccd59-fa20-412c-a508-e99b98a714a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Load the Model for Inference\n",
    "#\tFor making predictions on new data, you can load the model and tokenizer.\n",
    "\t\n",
    "# Load the model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('./sentiment_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./sentiment_tokenizer')\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "\tinputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\twith torch.no_grad():\n",
    "\t\toutputs = model(**inputs)\n",
    "\t\tlogits = outputs.logits\n",
    "\t\tprediction = torch.argmax(logits, dim=-1).item()\n",
    "\t\treturn \"positive\" if prediction == 1 else \"negative\"\n",
    "\n",
    "\t# Example prediction\n",
    "\tprint(predict_sentiment(\"This movie was amazing!\"))\n",
    "\tprint(predict_sentiment(\"I did not like this movie at all.\"))\n",
    "\t\n",
    "\n",
    "12. outputs.logits\n",
    "\tLogits: These are the raw scores produced by the model before applying any activation function like softmax. They represent the model's confidence in each class (in this case, sentiment classes)\t\n",
    "\t\n",
    "13. outputs = model(**inputs)\t\n",
    "\tModel: The model is a pre-trained transformer model loaded from the Hugging Face library.\n",
    "\tInputs: The **inputs syntax unpacks the dictionary of inputs, which typically includes input_ids and attention_mask, and passes them to the model for inference.\n",
    "\tOutputs: The model returns an object that includes various outputs, with logits being the raw, unnormalized scores for each class.\n",
    "\t\n",
    "14. Predicting the Sentiment:\n",
    "\tprediction = torch.argmax(logits, dim=-1).item()\n",
    "\t\n",
    "\ttorch.argmax: Finds the index of the highest value in logits, which corresponds to the predicted class. dim=-1 specifies that the operation is performed across the last dimension, which is the class dimension.\n",
    "\titem(): Converts the PyTorch tensor to a standard Python integer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-deep-learn)",
   "language": "python",
   "name": "venv-deep-learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
