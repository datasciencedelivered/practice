{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2eb85f-1b11-4674-81a2-0f9d1cb3f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399fe0a-4737-4ea8-8cb3-56a8e61916fe",
   "metadata": {},
   "source": [
    "## Ways to initiate a Model\n",
    "### Using AutoModel and AutoTokenizer  # when flexibility is needed the script can load a model based on say an argument to the script\n",
    "### Use specific model such as BertModel and BertTokenizer # Specific Model Architecture: You know exactly which model architecture you need (e.g., BERT) and you want to work with its base version.\n",
    "### Customization: You plan to customize the model architecture or use it in a way not directly covered by the predefined classes (like BertForSequenceClassification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709feab3-a022-4110-9fc2-09f3d71b72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using AutoModel and AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "486ce116-76bf-488d-b1ac-039797b87241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7632, 2045, 999, 2129, 2024, 2017, 1029]\n"
     ]
    }
   ],
   "source": [
    "# little bit playing with tokenizer\n",
    "\n",
    "#print(tokenizer.get_vocab())\n",
    "stmt = \"Hi there! How are you?\"\n",
    "#print(tokenizer.tokenize(stmt))\n",
    "#print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(stmt)))\n",
    "\n",
    "inputs = tokenizer(stmt, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e160f326-f62c-42f2-b4fe-6e67cf7bbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab5cea90-8bb7-426d-9850-351298efcd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0065,  0.0708, -0.2729,  ..., -0.3404,  0.2345,  0.4320],\n",
      "         [ 0.1477, -0.2803,  0.3758,  ..., -0.4016,  0.6521, -0.1745],\n",
      "         [-0.2468,  0.2844,  0.0446,  ..., -0.8503,  0.1914, -0.6120],\n",
      "         ...,\n",
      "         [-0.1852, -1.0877,  0.3731,  ..., -0.4977,  0.4553, -0.7094],\n",
      "         [-0.3255, -1.0539, -0.9465,  ...,  0.1774,  0.1054, -0.0724],\n",
      "         [ 0.5785, -0.2137, -0.2728,  ...,  0.2902, -0.4906, -0.2305]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9318, -0.3886, -0.8292,  0.8137,  0.5481, -0.1564,  0.9253,  0.2916,\n",
      "         -0.7400, -1.0000, -0.3505,  0.9223,  0.9817,  0.4951,  0.9641, -0.8294,\n",
      "         -0.5750, -0.6805,  0.2991, -0.6585,  0.7379,  1.0000,  0.1993,  0.3337,\n",
      "          0.4851,  0.9863, -0.8557,  0.9588,  0.9715,  0.7182, -0.7737,  0.1066,\n",
      "         -0.9897, -0.2154, -0.8522, -0.9912,  0.3565, -0.7940, -0.0439,  0.0625,\n",
      "         -0.9205,  0.2639,  1.0000, -0.2656,  0.3474, -0.3441, -1.0000,  0.2432,\n",
      "         -0.9272,  0.8800,  0.8521,  0.7104,  0.2036,  0.4562,  0.4888,  0.1115,\n",
      "         -0.0755,  0.0366, -0.2784, -0.6138, -0.5881,  0.5015, -0.8275, -0.9226,\n",
      "          0.8884,  0.7093, -0.1185, -0.2247, -0.1221, -0.1393,  0.9276,  0.3148,\n",
      "          0.3583, -0.9129,  0.4629,  0.3316, -0.7706,  1.0000, -0.7082, -0.9800,\n",
      "          0.7760,  0.6921,  0.6920, -0.1003,  0.2960, -1.0000,  0.5513, -0.0874,\n",
      "         -0.9925,  0.2506,  0.5974, -0.3183,  0.2961,  0.6732, -0.6069, -0.4638,\n",
      "         -0.3083, -0.8454, -0.3187, -0.3105,  0.0348, -0.2468, -0.4853, -0.4392,\n",
      "          0.3392, -0.4578, -0.5944,  0.3193, -0.2450,  0.6886,  0.5310, -0.3611,\n",
      "          0.5702, -0.9744,  0.6734, -0.4032, -0.9906, -0.7025, -0.9916,  0.6924,\n",
      "         -0.3658, -0.2780,  0.9771,  0.0276,  0.5353, -0.0512, -0.8781, -1.0000,\n",
      "         -0.7345, -0.6212, -0.1388, -0.3053, -0.9805, -0.9732,  0.6559,  0.9680,\n",
      "          0.2185,  0.9999, -0.3141,  0.9618, -0.2196, -0.5727,  0.5221, -0.4889,\n",
      "          0.7615,  0.5862, -0.6506,  0.1762, -0.2653,  0.3776, -0.7536, -0.2010,\n",
      "         -0.6290, -0.9633, -0.4383,  0.9661, -0.4303, -0.9078,  0.1799, -0.2387,\n",
      "         -0.6315,  0.8710,  0.7401,  0.4297, -0.3265,  0.4345,  0.2220,  0.6287,\n",
      "         -0.9031, -0.0264,  0.5126, -0.3087, -0.7576, -0.9798, -0.4278,  0.6162,\n",
      "          0.9929,  0.7958,  0.3453,  0.7495, -0.3034,  0.7458, -0.9661,  0.9843,\n",
      "         -0.2590,  0.2934,  0.1997,  0.3783, -0.9176, -0.0751,  0.8909, -0.5987,\n",
      "         -0.8781, -0.2012, -0.5307, -0.4689, -0.7687,  0.6340, -0.3048, -0.3022,\n",
      "         -0.0821,  0.9452,  0.9858,  0.8279,  0.0468,  0.7931, -0.9194, -0.4910,\n",
      "          0.0457,  0.2765,  0.1312,  0.9953, -0.6835, -0.1321, -0.9480, -0.9881,\n",
      "         -0.1027, -0.9308, -0.1323, -0.6996,  0.7091,  0.1926,  0.4999,  0.5475,\n",
      "         -0.9909, -0.7666,  0.4128, -0.4994,  0.4672, -0.2123,  0.5406,  0.8929,\n",
      "         -0.6415,  0.8170,  0.9491, -0.8395, -0.8271,  0.8179, -0.3407,  0.8878,\n",
      "         -0.6970,  0.9891,  0.9201,  0.8663, -0.9393, -0.6329, -0.9006, -0.6898,\n",
      "         -0.0406, -0.0715,  0.8511,  0.7341,  0.4189,  0.5427, -0.7167,  0.9987,\n",
      "         -0.5902, -0.9642, -0.3222, -0.1120, -0.9869,  0.8689,  0.3879,  0.1472,\n",
      "         -0.4500, -0.7879, -0.9724,  0.8867,  0.1332,  0.9881, -0.1708, -0.9569,\n",
      "         -0.5563, -0.9416, -0.2138, -0.2571, -0.1026, -0.1646, -0.9735,  0.5507,\n",
      "          0.5628,  0.6035, -0.6602,  0.9993,  1.0000,  0.9737,  0.9259,  0.9491,\n",
      "         -0.9998, -0.6456,  1.0000, -0.9899, -1.0000, -0.9467, -0.6708,  0.4052,\n",
      "         -1.0000, -0.2141,  0.0027, -0.9351,  0.6129,  0.9795,  0.9960, -1.0000,\n",
      "          0.8554,  0.9578, -0.7638,  0.9651, -0.4750,  0.9750,  0.6121,  0.3785,\n",
      "         -0.3387,  0.3552, -0.9070, -0.8942, -0.4381, -0.6959,  0.9970,  0.1874,\n",
      "         -0.8386, -0.9321,  0.3154, -0.1376, -0.4156, -0.9783, -0.1987,  0.5702,\n",
      "          0.8360,  0.1720,  0.3501, -0.7094,  0.3164, -0.2296,  0.3292,  0.7750,\n",
      "         -0.9316, -0.4907, -0.0382, -0.4456, -0.5926, -0.9707,  0.9749, -0.5046,\n",
      "          0.8321,  1.0000,  0.0438, -0.9194,  0.7118,  0.2658, -0.0671,  1.0000,\n",
      "          0.7853, -0.9796, -0.6752,  0.4533, -0.6154, -0.6319,  0.9996, -0.1995,\n",
      "         -0.6058, -0.4739,  0.9824, -0.9889,  0.9921, -0.9385, -0.9754,  0.9781,\n",
      "          0.9443, -0.7841, -0.7288,  0.2513, -0.5723,  0.3193, -0.9707,  0.7610,\n",
      "          0.5763, -0.1195,  0.9092, -0.8868, -0.6961,  0.2811, -0.6483, -0.0176,\n",
      "          0.9204,  0.6275, -0.3631,  0.0507, -0.3594, -0.3315, -0.9838,  0.3724,\n",
      "          1.0000, -0.2250,  0.6640, -0.3279, -0.1021, -0.1943,  0.4788,  0.6421,\n",
      "         -0.2927, -0.8830,  0.6961, -0.9825, -0.9853,  0.8390,  0.2256, -0.4064,\n",
      "          1.0000,  0.4742,  0.0717,  0.3492,  0.9833,  0.0797,  0.7162,  0.8481,\n",
      "          0.9877, -0.2296,  0.6756,  0.8943, -0.8514, -0.4278, -0.6783, -0.0284,\n",
      "         -0.9206,  0.0524, -0.9727,  0.9763,  0.9285,  0.4195,  0.2499,  0.5027,\n",
      "          1.0000, -0.4926,  0.6650, -0.4582,  0.8941, -0.9995, -0.9072, -0.4406,\n",
      "         -0.1190, -0.7144, -0.3774,  0.3975, -0.9789,  0.7507,  0.5223, -0.9959,\n",
      "         -0.9932,  0.0226,  0.9123,  0.1010, -0.9818, -0.7815, -0.6614,  0.5200,\n",
      "         -0.2278, -0.9552, -0.0077, -0.3976,  0.5116, -0.1778,  0.6700,  0.7925,\n",
      "          0.7409, -0.4274, -0.3918, -0.1049, -0.8497,  0.9095, -0.8768, -0.8881,\n",
      "         -0.3143,  1.0000, -0.5546,  0.8513,  0.7476,  0.7472, -0.0948,  0.2556,\n",
      "          0.9148,  0.2746, -0.6533, -0.7704, -0.7419, -0.4171,  0.7486,  0.3121,\n",
      "          0.5691,  0.8294,  0.8049,  0.0984, -0.0428, -0.0703,  0.9998, -0.2341,\n",
      "         -0.1268, -0.5222,  0.0186, -0.4376, -0.5058,  1.0000,  0.2735,  0.3797,\n",
      "         -0.9907, -0.8443, -0.9439,  1.0000,  0.8461, -0.8497,  0.7000,  0.6254,\n",
      "         -0.1538,  0.8682, -0.1710, -0.3985,  0.3363,  0.1654,  0.9579, -0.5812,\n",
      "         -0.9771, -0.6997,  0.4659, -0.9753,  0.9999, -0.6404, -0.2522, -0.4730,\n",
      "         -0.0849,  0.3090, -0.0825, -0.9876, -0.2214,  0.2820,  0.9645,  0.3813,\n",
      "         -0.7185, -0.9424,  0.6842,  0.7642, -0.8976, -0.9537,  0.9672, -0.9925,\n",
      "          0.5876,  1.0000,  0.3820, -0.1390,  0.2351, -0.4784,  0.4155, -0.3341,\n",
      "          0.8025, -0.9728, -0.2944, -0.1972,  0.3504, -0.1336, -0.1894,  0.7931,\n",
      "          0.1982, -0.7004, -0.6832, -0.0550,  0.4429,  0.9026, -0.2960, -0.2499,\n",
      "          0.0615, -0.1661, -0.9438, -0.1917, -0.4926, -1.0000,  0.7686, -1.0000,\n",
      "          0.4074,  0.0621, -0.2622,  0.8932,  0.4068,  0.4993, -0.8005, -0.7543,\n",
      "          0.6470,  0.7692, -0.2939, -0.5080, -0.7649,  0.3874, -0.0465,  0.1515,\n",
      "         -0.4496,  0.7755, -0.2450,  1.0000,  0.1824, -0.8425, -0.9820,  0.1515,\n",
      "         -0.3091,  1.0000, -0.9412, -0.9632,  0.5511, -0.7953, -0.8830,  0.4261,\n",
      "          0.0617, -0.8097, -0.9246,  0.9727,  0.9433, -0.6931,  0.4729, -0.3695,\n",
      "         -0.6539,  0.0333,  0.7967,  0.9871,  0.4661,  0.9094,  0.5283, -0.1171,\n",
      "          0.9792,  0.2176,  0.5199,  0.1384,  1.0000,  0.3948, -0.9279,  0.2841,\n",
      "         -0.9823, -0.2391, -0.9644,  0.3325,  0.2981,  0.9204, -0.2442,  0.9614,\n",
      "         -0.7312,  0.0384, -0.6511, -0.2484,  0.4638, -0.9302, -0.9844, -0.9864,\n",
      "          0.5822, -0.5263, -0.0713,  0.2114,  0.1150,  0.4424,  0.5430, -1.0000,\n",
      "          0.9546,  0.4875,  0.8888,  0.9681,  0.7647,  0.4731,  0.3205, -0.9901,\n",
      "         -0.9865, -0.3373, -0.2178,  0.7476,  0.7130,  0.9377,  0.4920, -0.5261,\n",
      "         -0.2308, -0.2657, -0.5899, -0.9948,  0.5401, -0.3676, -0.9738,  0.9689,\n",
      "         -0.3458, -0.1845,  0.1039, -0.7857,  0.9530,  0.8531,  0.4151,  0.0330,\n",
      "          0.4689,  0.8984,  0.9686,  0.9817, -0.7229,  0.9093, -0.4434,  0.5440,\n",
      "          0.7719, -0.9567,  0.0976,  0.5236, -0.4602,  0.2801, -0.2581, -0.9768,\n",
      "          0.6896, -0.3282,  0.6215, -0.5214,  0.0971, -0.4416, -0.1077, -0.7286,\n",
      "         -0.7186,  0.7110,  0.6098,  0.9294,  0.7485, -0.0358, -0.7442, -0.1545,\n",
      "         -0.7121, -0.9179,  0.9461, -0.0219, -0.2250,  0.5390, -0.0959,  0.7814,\n",
      "         -0.0268, -0.3565, -0.3596, -0.6721,  0.9032, -0.5417, -0.5627, -0.5961,\n",
      "          0.7698,  0.3471,  1.0000, -0.7174, -0.8460, -0.4259, -0.3856,  0.4989,\n",
      "         -0.6623, -1.0000,  0.4758, -0.3494,  0.6277, -0.6533,  0.7908, -0.6317,\n",
      "         -0.9869, -0.2963,  0.4000,  0.6958, -0.4785, -0.6137,  0.6968,  0.0661,\n",
      "          0.9756,  0.9162, -0.4371,  0.2935,  0.7394, -0.6243, -0.7495,  0.9360]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "tensor([[[ 0.0065,  0.0708, -0.2729,  ..., -0.3404,  0.2345,  0.4320],\n",
      "         [ 0.1477, -0.2803,  0.3758,  ..., -0.4016,  0.6521, -0.1745],\n",
      "         [-0.2468,  0.2844,  0.0446,  ..., -0.8503,  0.1914, -0.6120],\n",
      "         ...,\n",
      "         [-0.1852, -1.0877,  0.3731,  ..., -0.4977,  0.4553, -0.7094],\n",
      "         [-0.3255, -1.0539, -0.9465,  ...,  0.1774,  0.1054, -0.0724],\n",
      "         [ 0.5785, -0.2137, -0.2728,  ...,  0.2902, -0.4906, -0.2305]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "#print(help(outputs))\n",
    "#print(outputs.logits)   #base model does not have this attribute for output instead use last_hidden_state\n",
    "logits = outputs.last_hidden_state\n",
    "print(logits) # logits # Since this is not a classification problem there is not further classes to be derived\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-deep-learn)",
   "language": "python",
   "name": "venv-deep-learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
